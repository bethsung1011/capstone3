import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import altair as alt
import streamlit as st
import pandas as pd
import numpy as np
import time
import requests

from streamlit_lottie import st_lottie

import matplotlib
import matplotlib.pyplot as plt
from matplotlib.backends.backend_agg import RendererAgg
from matplotlib.figure import Figure
import seaborn as sns
import statsmodels
from statsmodels.nonparametric.smoothers_lowess import lowess
import random
matplotlib.use("Agg")

_lock = RendererAgg.lock
plt.style.use('default')

# SETUP ------------------------------------------------------------------------

def load_lottieurl(url: str):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()

lottie_url1 = "https://assets5.lottiefiles.com/private_files/lf30_6jzgknvg.json"
lottie_json1 = load_lottieurl(lottie_url1)
st_lottie(lottie_json1)


st.title('Okcupid Match Making Recommender')
st.write('')
st.write('')
st.write('')


# # SIDE BAR ------------------------------------------------------------------------

# # Cached function that returns a mutable object with a random number in the range 0-100
# @st.cache(allow_output_mutation=True)
# def seed():
#     return {'seed': random.randint(0, 100)} # Mutable (dict)

# # Random state for points generation randomly selected by calling the cached function seed()
# # In this way the points distribution generated by make_blobs is conserved when app is rerun
# random_state = seed()


# # Button to reset points by mutating the cached dict value
# if st.sidebar.button('Reset points', key='123'):
#     random_state['seed'] = random.randint(0, 100) # Mutated cached value


# # Showing the current random_state
# st.sidebar.write('Seed = ', random_state['seed'])


# # Slider to select the standard deviation of clusters generated by make_blobs generator
# cluster_std = st.sidebar.slider('Dispersion', 0.2, 3.0, 0.2, 0.2)


# # Dropdown list to select number of clusters
# n_clusters = st.sidebar.selectbox('Number of clusters', range(1, 10))


# ROW 0 ------------------------------------------------------------------------
row0_spacer1, row0_1_1, row0_spacer2, row0_1_2, row0_spacer3 = st.beta_columns(
    (.1, 1.6, .1, 3.5, .1)
    )

with row0_1_1:
    lottie_url2 = "https://assets6.lottiefiles.com/packages/lf20_sen1ai7d.json"
    lottie_json = load_lottieurl(lottie_url2)
    st_lottie(lottie_json)

with row0_1_2:
    row0_1_2.write("""“Love doesn’t make the world go round. Love is what makes the ride worthwhile” – Franklin P. Jones  """)

st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')

# ROW 0 ------------------------------------------------------------------------
row0_spacer1, row0_5_1, row0_spacer2, row0_5_2, row0_spacer3 = st.beta_columns(
    (.1, 1.6, .1, 3.5, .1)
    )

with row0_5_1:
    lottie_url3 = "https://assets4.lottiefiles.com/packages/lf20_utsfwa3k.json"
    lottie_json = load_lottieurl(lottie_url3)
    st_lottie(lottie_json)

with row0_5_2:
    row0_5_2.write("""
    “’Tis better to have loved and lost, than never to have loved at all”  – Alfred, Lord Tennyson 
    """)
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')

# ROW 0 ------------------------------------------------------------------------
row0_spacer1, row0_5_1, row0_spacer2, row0_5_2, row0_spacer3 = st.beta_columns(
    (.1, 1.6, .1, 3.5, .1)
    )

with row0_5_1:

    lottie_url4 = "https://assets1.lottiefiles.com/packages/lf20_gghk4m0m.json"
    lottie_json = load_lottieurl(lottie_url4)
    st_lottie(lottie_json)



# "https://assets3.lottiefiles.com/packages/lf20_n5icqxkw.json"
with row0_5_2:
    row0_5_2.write("""“We come to love not by finding a perfect person, but by learning to see an imperfect person perfectly.” """)
    row0_5_2.write('')
    row0_5_2.write('')

st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')

# ROW 0.5 ------------------------------------------------------------------------
# row0_spacer1, row0_1, row0_spacer2, row0_2, row0_spacer3 = st.beta_columns(
#     (.1, 1.6, .1, 3.5, .1)
#     )

# with row0_1:

#     lottie_url5 ="https://assets10.lottiefiles.com/packages/lf20_aeo5ikeu.json"
#     lottie_json5 = load_lottieurl(lottie_url5)
#     st_lottie(lottie_json)

# #  "https://assets3.lottiefiles.com/packages/lf20_hewaysm0.json"
# with row0_2:
#     row0_2.write("""
#     “The best and most beautiful things in the world cannot be seen or even touched. They must be felt with the heart.”  \n
#     – Helen Keller """)
#     row0_2.write('')
#     row0_2.write('')

# st.write('')
# st.write('')
# st.write('')
# st.write('')
# st.write('')
# st.write('')



# ROW 1 ------------------------------------------------------------------------

row1_spacer1, row1_1, row1_spacer2, row1_2, row1_spacer3 = st.beta_columns(
    (.1, 2, 1.5, 1, .1)
    )



@st.cache(allow_output_mutation=True)
def get_pd():
    #plyer data
    col_list2 = ['id_','nickname','age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',
       'drugs', 'education', 'height', 'job', 'offspring', 'pets', 'religion',
       'sign', 'smokes','headshot_url']

    player_data_ = pd.read_csv('https://github.com/bethsung1011/capstone_3/blob/main/profile1.csv?raw=True',
                                low_memory=False, usecols=col_list2)

    return player_data_

player_data_ = get_pd()


# ROW 2 ------------------------------------------------------------------------

row2_spacer1, row2_1, row2_spacer2, row2_2, row2_spacer3,  row2_3, row2_spacer4= st.beta_columns(
    (.1,1.6,.1,1.6,.1,1.6,.1)
    )

with row2_1:
    records=player_data_['nickname'].to_list()
        # 'Miranda', 'Ken', 'Beebeep Bajeep', 'puppy', 'Samu', 'Wayne', 'Tom', 'George Timberman', 'Fox Creek', 'doge', 'Roonie', 'Toby', 'Somebody', 'j']
    selected_data = st.selectbox('Select Who You Are', options=records)


with row2_2:

    url = {'Miranda': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5209176-035clefairy.png',
 'Ken': 'https://comicvine1.cbsistatic.com/uploads/original/6/63099/1998241-ep067.png',
 'Beebeep Bajeep': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198759-068machamp.png',
 'puppy': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198898-003venusaur-mega.png',
 'Samu': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5213189-042golbat.png',
 'Wayne': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198880-007squirtle.png',
 'Tom': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/4357615-250px-094gengar.png',
 'George Timberman': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5215180-175togepi.png',
 'Fox Creek': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198871-143snorlax.png',
 'doge': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198763-052meowth.png',
 'Roonie': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5212960-107hitmonchan.png',
 'Toby': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198641-006charizard-mega_y.png',
 'Somebody': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198809-057primeape.png',
 'j': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5212919-095onix.png'}


    st.subheader('About Me')
    st.image(url.get(selected_data), width=200)


with row2_3:


    player_filter = player_data_.loc[player_data_['nickname'] == selected_data]
  
    st.subheader('     ')
    st.text(        f"Name: {player_filter['nickname'].to_string(index=False).lstrip()}"        )
    st.text(        f"Age: {player_filter['age'].to_string(index=False).lstrip()}"        )
    st.text(        f"Status: {player_filter['status'].to_string(index=False).lstrip()}"        )
    st.text(        f"Orientation: {player_filter['orientation'].to_string(index=False).lstrip()}"        )
    st.text(        f"Diet: {player_filter['diet'].to_string(index=False).lstrip()}"        )
    st.text(        f"Job: {player_filter['job'].to_string(index=False).lstrip()}"        )    
    # st.text(        f"Job: {player_filter['job'].astype(int).to_string(index=False).lstrip()}"        )
    st.text(' ')

st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')


# ROW 3 - 1 ------------------------------------------------------------------------

# row3_spacer1, row3_1, row3_spacer2, row3_2, row3_spacer3 = st.beta_columns(
#     (.1, 1.6, .1, 1.6, .1)
#     )

# @st.cache(suppress_st_warning=True) 
@st.cache(allow_output_mutation=True)
def get_pd():
    lookup={'Miranda':'https://github.com/bethsung1011/capstone_3/blob/main/id_59946.csv?raw=True', 
    'Ken':'https://github.com/bethsung1011/capstone_3/blob/main/id_59947.csv?raw=True', 
    'Beebeep Bajeep':'https://github.com/bethsung1011/capstone_3/blob/main/id_59948.csv?raw=True', 
    'puppy':'https://github.com/bethsung1011/capstone_3/blob/main/id_59949.csv?raw=True', 
    'Samu':'https://github.com/bethsung1011/capstone_3/blob/main/id_59950.csv?raw=True',
    'Wayne':'https://github.com/bethsung1011/capstone_3/blob/main/id_59951.csv?raw=True', 
    'Tom':'https://github.com/bethsung1011/capstone_3/blob/main/id_59952.csv?raw=True', 
    'George Timberman':'https://github.com/bethsung1011/capstone_3/blob/main/id_59953.csv?raw=True', 
    'Fox Creek':'https://github.com/bethsung1011/capstone_3/blob/main/id_59954.csv?raw=True', 
    'doge':'https://github.com/bethsung1011/capstone_3/blob/main/id_59955.csv?raw=True', 
    'Roonie':'https://github.com/bethsung1011/capstone_3/blob/main/id_59956.csv?raw=True', 
    'Toby':'https://github.com/bethsung1011/capstone_3/blob/main/id_59957.csv?raw=True',   
    'Somebody':'https://github.com/bethsung1011/capstone_3/blob/main/id_59958.csv?raw=True', 
    'j':'https://github.com/bethsung1011/capstone_3/blob/main/id_59959.csv?raw=True'}

    #plyer match info
    col_list2 = ['id', 'age', 'status', 'sex', 'orientation', 'body_type', 'diet',
    'drinks', 'drugs', 'education', 'height', 'job', 'offspring', 'pets',
    'religion', 'sign', 'smokes', 'match percentage']
    
    url=lookup.get(selected_data)   
    player_match_ = pd.read_csv(url,low_memory=False, usecols=col_list2)
    return player_match_

player_match_ = get_pd()


# with row3_1:


# st.line_chart(player_match_)
# st.area_chart(player_match_)
# st.bar_chart(player_match_[:20])
# st.pyplot(player_match_)
# st.altair_chart(player_match_[:20])
# st.vega_lite_chart(player_match_)
# st.plotly_chart(player_match_)
# st.bokeh_chart(player_match_)
# st.pydeck_chart(player_match_)
# st.deck_gl_chart(player_match_)
# st.graphviz_chart(player_match_)


st.header('Find My Match with SVD Attributes')

def click():
    if st.button('Hit me') : 

        st.text('Starting a long computation...')
        # Add a placeholder
        latest_iteration = st.empty()
        bar = st.progress(0)

        for i in range(100):
            # Update the progress bar with each iteration.
            latest_iteration.text(f'Iteration {i+1}')
            bar.progress(i + 1)
            time.sleep(0.1)

        st.text('...and now we\'re done!')

        st.write("## Top 20 Match Mates")
        player_match_.iloc[:20]


click()

st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
 
@st.cache(allow_output_mutation=True)
def get_pd():
    lookup_c={'Miranda':'https://github.com/bethsung1011/capstone_3/blob/main/c_59946.csv?raw=True', 
    'Ken':'https://github.com/bethsung1011/capstone_3/blob/main/c_59947.csv?raw=True', 
    'Beebeep Bajeep':'https://github.com/bethsung1011/capstone_3/blob/main/c_59948.csv?raw=True', 
    'puppy':'https://github.com/bethsung1011/capstone_3/blob/main/c_59949.csv?raw=True', 
    'Samu':'https://github.com/bethsung1011/capstone_3/blob/main/c_59950.csv?raw=True',
    'Wayne':'https://github.com/bethsung1011/capstone_3/blob/main/c_59951.csv?raw=True', 
    'Tom':'https://github.com/bethsung1011/capstone_3/blob/main/c_59952.csv?raw=True', 
    'George Timberman':'https://github.com/bethsung1011/capstone_3/blob/main/c_59953.csv?raw=True', 
    'Fox Creek':'https://github.com/bethsung1011/capstone_3/blob/main/c_59954.csv?raw=True', 
    'doge':'https://github.com/bethsung1011/capstone_3/blob/main/c_59955.csv?raw=True', 
    'Roonie':'https://github.com/bethsung1011/capstone_3/blob/main/c_59956.csv?raw=True', 
    'Toby':'https://github.com/bethsung1011/capstone_3/blob/main/c_59957.csv?raw=True',   
    'Somebody':'https://github.com/bethsung1011/capstone_3/blob/main/c_59958.csv?raw=True', 
    'j':'https://github.com/bethsung1011/capstone_3/blob/main/c_59959.csv?raw=True'}

    #plyer match info
    col_list2 = ['level_0', 'index', 'age', 'status', 'sex', 'orientation', 'body_type',
       'diet', 'drinks', 'drugs', 'education', 'ethnicity', 'height', 'income',
       'job', 'last_online', 'location', 'offspring', 'pets', 'religion',
       'sign', 'smokes', 'speaks', 'profile_text', 'Total Words', 'id_']
    
    url_c=lookup_c.get(selected_data) 
    # url_c=lookup_c.get(selected_data)   
    player_c_match_ = pd.read_csv(url_c,low_memory=False, usecols=col_list2)
    return player_c_match_

player_c_match_ = get_pd()



st.header('Find Another Match with CountVectorizer')

def click():
    if st.button('Press me') : 

        st.text('Starting a long computation...')
        # Add a placeholder
        latest_iteration = st.empty()
        bar = st.progress(0)

        for i in range(100):
            # Update the progress bar with each iteration.
            latest_iteration.text(f'Iteration {i+1}')
            bar.progress(i + 1)
            time.sleep(0.1)

        st.text('...and now we\'re done!')

        st.write("## Top 20 Match Mates")
        player_c_match_


click()


st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')

@st.cache(allow_output_mutation=True)
def get_pd():
    lookup_l={'Miranda':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True', 
    'Ken':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',
    'Beebeep Bajeep':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',
    'puppy':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',
    'Samu':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',
    'Wayne':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',
    'Tom':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True', 
    'George Timberman':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',
    'Fox Creek':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',
    'doge':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True', 
    'Roonie':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',
    'Toby':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True',   
    'Somebody':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True', 
    'j':'https://github.com/bethsung1011/capstone_3/blob/main/test_lda.csv?raw=True'}

    #plyer match info
    col_list2 = ['id_', 'age', 'status', 'sex', 'orientation', 'body_type', 'diet',
       'drinks', 'drugs', 'education', 'ethnicity', 'height', 'income', 'job',
       'last_online', 'location', 'offspring', 'pets', 'religion', 'sign',
       'smokes', 'speaks', 'profile_text', 'Total Words', 'lda_recommend']
    
    url_l=lookup_l.get(selected_data) 
    # url_c=lookup_c.get(selected_data)   
    player_l_match_ = pd.read_csv(url_l,low_memory=False, usecols=col_list2)
    return player_l_match_

player_l_match_ = get_pd()



st.header('Find Another Match with Latent Dirichlet Allocation')

def click():
    if st.button('Challenge me') : 

        st.text('Starting a long computation...')
        # Add a placeholder
        latest_iteration = st.empty()
        bar = st.progress(0)

        for i in range(100):
            # Update the progress bar with each iteration.
            latest_iteration.text(f'Iteration {i+1}')
            bar.progress(i + 1)
            time.sleep(0.1)

        st.text('...and now we\'re done!')

        st.write("## Top 20 Match Mates")
        player_l_match_


click()

st.write('')
st.write('')
st.write('')
st.write('')
st.write('')
st.write('')

@st.cache(allow_output_mutation=True)
def get_pd():

    col_list2 = ['id_', 'age', 'status', 'sex', 'orientation', 'body_type', 'diet',
       'drinks', 'drugs', 'education', 'ethnicity', 'height', 'income', 'job',
       'last_online', 'location', 'offspring', 'pets', 'religion', 'sign',
       'smokes', 'speaks', 'profile_text', 'Total Words', 'lda_recommend']
     
    df = pd.read_csv('https://github.com/bethsung1011/capstone_3/blob/main/concat_with_lda.csv?raw=True', usecols=col_list2, error_bad_lines=False)
    return df


df = get_pd()


# df[(df["Reporting Status"] == rprt_status) 
# & (df["Source"] == src) 
# & (df["Contract Type"] == cntrct_type) 
# & (df["Country"] == country)]["CPM"]

# msk1 = df["Reporting Status"] == rprt_status if rprt_status in lst_rprt_status else True
# msk2 = df["Source"] == src if src in lst_src else True
# msk3 = df["Contract Type"] == cntrct_type if cntrct_type in lst_cntrct_type else True
# msk4 = df["Country"] == country if country in lst_country else True

# df_filtered = (df[msk1 & msk2 & msk3 & msk4])["CPM"]

st.sidebar.title('User Database')


st.write('sex')
sex = df['sex'].unique()
sex_choice = st.sidebar.selectbox('Select sex:',sex)
msk1 = df["sex"] == sex_choice if sex_choice in sex else True
filtered_sex = df[df['sex'] == sex_choice].iloc[:20,0:9]
st.dataframe(filtered_sex)

st.write('orientation')
orientation = df['orientation'].unique()
orientation_choice= st.sidebar.selectbox('Select orientation:', orientation)
msk2 = df["orientation"] == orientation_choice if orientation_choice in orientation else True
filtered_orientation = df[df['orientation'] == orientation_choice].iloc[:20,0:9]
st.dataframe(filtered_orientation)

st.write('age')
age = np.arange(18,100,1)
age_choice = st.sidebar.slider('choose age', 18, 100, 30)
msk3 = df["age"] == age_choice if age_choice in age else True
filtered_age = df[df['age'] == age_choice].iloc[:20,0:9]
st.dataframe(filtered_age)

# st.dataframe(filtered_age)

# if choice == sex_choice:
#     st.dataframe(filtered_sex)
# elif 

# body_type = df['body_type'].unique()    
# for input_ in [sex_choice, orientation_choice, age_choice]: 
#     if input_ 


# body_type_choice =  st.sidebar.selectbox('Select body type', body_type)
# msk4 = df["body_type"] == body_type_choice if body_type_choice in body_type else True
# filtered_body_type = df[df['body_type'] == body_type_choice]
# df_filtered = (df[msk1 & msk2 & msk3 & msk4])["smoke"]
# df_filtered = (df[msk1 & msk2 & msk3 & msk4])["age"]
# st.dataframe(df_filtered)

# body_type = df["age"].loc[df["body_type"] == make_choice]

# diet = df['diet'].unique()
# diet_choice = st.sidebar.selectbox('Select diet', diet)

# drinks = df['drinks'].unique()
# drinks_choice = st.sidebar.selectbox('Select drinks', drinks)

# drugs = df['drugs'].unique()
# drugs_choice =  st.sidebar.selectbox('Select drugs', drugs)

# education = df['education'].unique()
# education_choice =  st.sidebar.selectbox('Select education',education)

# ethnicity = df['ethnicity'].unique()
# ethnicity_choice =  st.sidebar.selectbox('Select ethnicity', ethnicity)

# pets = df['pets'].unique()
# pets_choice =  st.sidebar.selectbox('Select pets', pets)

# religion = df['religion'].unique()
# religion_choice =  st.sidebar.selectbox('Select religion',religion)

# smokes = df['smokes'].unique()
# smokes_choice =  st.sidebar.selectbox('Select smokes', smokes)




# religion_choice =  st.sidebar.selectbox('Select religion', [1,2,3])

# years = df["year"].loc[df["make"] == make_choice]
# year_choice = st.sidebar.selectbox('', years) 

# models = df["model"].loc[df["make"] == make_choice]
# model_choice = st.sidebar.selectbox('', models)
# engines = df['engine'].loc[df["make"] == make_choice]
# engine_choice = st.sidebar.selectbox('', engines)



# create bar chart
# st.write("## TOP SUGGESTIONS")

# chart = alt.Chart(player_match_[:20]).mark_bar().encode(
#     x=alt.X("match percentage"),
#     y=alt.Y('id', sort='-x'),
#     opacity=alt.value(1),
#     color=alt.condition(
#     alt.datum.Name == player_match_['id'][0],  # If it's the top ranked prediction
#         alt.value('#f63366'),     #  sets the bar to the streamlit pink.
#         alt.value('grey')  ) # else this colour
# ).properties(width=400)


# text = chart.mark_text(
#     align='left',
#     baseline='middle',
#     binSpacing=4,
#     dx=3  # Nudges text to right so it doesn't appear on top of the bar
# ).encode(
#     text=alt.Text('match percentage', format='')
# )

# st.altair_chart(chart+text)


# chart=alt.Chart(player_match_[:20]).mark_bar().encode(
#     x="id",
#     y="match percentage",
#     # The highlight will be set on the result of a conditional statement
#     color=alt.condition(
#         alt.datum.year == player_match_['id'][0],  # If the year is 1810 this test returns True,
#         alt.value('orange'),     # which sets the bar orange.
#         alt.value('steelblue')   # And if it's not true it sets the bar steelblue.
#     )
# ).properties(width=600)

# st.altair_chart(chart)


# chart=alt.Chart(player_match_[:20]).mark_bar().encode(
#     x='id',
#     y='match percentage'
# )
# st.altair_chart(chart)

# ROW 3 - 1 ------------------------------------------------------------------------
# with row3_2:




# import plotly.figure_factory as ff
# x=player_match_[:20]['id'].to_list()
# y=player_match_[:20]['match percentage'].to_list()
# fig = ff.create_distplot(x,y,bin_size=[.1, .25, .5])

# # Plot!
# st.plotly_chart(fig, use_container_width=True)


# with st.beta_container():
#     st.write("This is inside the container")
#     # You can call any Streamlit command, including custom components:
#     st.bar_chart(player_match_[:20]['match percentage'])
#     st.write("This is outside the container")

# player_match_[:20]['id'],



# st.vega_lite_chart(player_match_[:20], {
#      'mark': {'type': 'circle', 'tooltip': True},
#     'encoding': {
#         'x': {'field': 'id', 'type': 'quantitative'},
#          'y': {'field': 'match percentage', 'type': 'quantitative'},
#          'size': {'field': 'c', 'type': 'quantitative'},
#          'color': {'field': 'c', 'type': 'quantitative'},
#      },
#  })


# ROW 4 ------------------------------------------------------------------------

row4_spacer1, row4_1, row4_spacer2, row4_2, row4_spacer3 = st.beta_columns(
    (.1, 1.6, .1, 1.6, .1)
    )

with row4_1:
    lottie_url = "https://assets9.lottiefiles.com/packages/lf20_xldshlit.json"
    lottie_json = load_lottieurl(lottie_url)
    st_lottie(lottie_json)


# with row4_2:


# ROW 5 ------------------------------------------------------------------------
row5_spacer1, row5_1, row5_spacer2 = st.beta_columns((.1, 3.2, .1))

with row5_1:
    st.markdown('___')
    about = st.beta_expander('About/Additional Info')
    with about:
        '''
        Thanks for checking out my app! It was built entirely using [okcupid]
        (https://www.kaggle.com/andrewmvd/okcupid-profiles/) data. Special thanks to [Larxel]
        (https://www.kaggle.com/andrewmvd) and [Anna Durbanova](https://www.kaggle.com/annadurbanova) who do a great job providing this kaggle
        data, helping okcupid EDA on initial stage! This is the first time I have ever built something like this, 
        so any comments or feedback is greatly appreciated. I hope you enjoy!

        This app is a dashboard that runs an recommender on specific users provided in Galvanize 2021 Spring Full Time Online Cohort.
        It has logged 14 total anonymous and randomly suffled people.
        
        **Select Who You Are** 
            - Display information of participants along with picture.
        
        **SVD Attributes** 
            - Using non-verval attributes, SVD model was made and recommender provides cosine similarity of best match. 
        
        **CountVectorizer** 
            - Using Natural Language Process, CountVectorizer model provides similarity recommending.
        
        **Latent Dirichlet Allocation** 
            - Using Natural Language Process, Latent Dirichlet Allocation model provides top 20 recommendations.
        
        **Side Filter** 
            - Filter your options and search for specific individual like database. 
        
        ### Beth Sung, April 2021
        '''
st.write('')
st.write('')
st.write('')
st.write('')
st.write('Thanks!')
st.write('made by [Beth Sung](https://www.linkedin.com/in/beth-sung/)')


# st.text('This will appear first')
# # Appends some text to the app.

# my_slot1 = st.empty()
# # Appends an empty slot to the app. We'll use this later.

# my_slot2 = st.empty()
# # Appends another empty slot.

# st.text('This will appear last')
# # Appends some more text to the app.

# my_slot1.text('This will appear second')
# # Replaces the first empty slot with a text string.

# my_slot2.line_chart(np.random.randn(20, 2))
# # Replaces the second empty slot with a chart.


# progress_bar = st.progress(0)
# status_text = st.empty()
# chart = st.line_chart(np.random.randn(10, 2))

# for i in range(100):
#     # Update progress bar.
#     progress_bar.progress(i + 1)

#     new_rows = np.random.randn(10, 2)

#     # Update status text.
#     status_text.text(
#         'The latest random number is: %s' % new_rows[-1, 1])

#     # Append data to the chart.
#     chart.add_rows(new_rows)

#     # Pretend we're doing some computation that takes time.
#     time.sleep(0.1)

# status_text.text('Done!')
# st.balloons()




# import numpy as np
# import time

# # Get some data.
# data = np.random.randn(10, 2)

# # Show the data as a chart.
# chart = st.line_chart(data)

# # Wait 1 second, so the change is clearer.
# time.sleep(1)

# # Grab some more data.
# data2 = np.random.randn(10, 2)

# # Append the new data to the existing chart.
# chart.add_rows(data2)



# import streamlit as st
# import pandas as pd
# import numpy as np

# dataframe = np.random.randn(10, 20)
# st.dataframe(dataframe)


# dataframe = pd.DataFrame(
#     np.random.randn(10, 20),
#     columns=('col %d' % i for i in range(20)))

# st.dataframe(dataframe.style.highlight_max(axis=0))



# dataframe = pd.DataFrame(
#     np.random.randn(10, 20),
#     columns=('col %d' % i for i in range(20)))
# st.table(dataframe)


# import streamlit as st
# x = st.slider('x')  # 👈 this is a widget
# st.write(x, 'squared is', x * x)












# # import streamlit as st

# # # Add a selectbox to the sidebar:
# # st.sidebar.selectbox(
# #     'How would you like to be contacted?',
# #     ('Email', 'Home phone', 'Mobile phone')
# # )



# # # Add a slider to the sidebar:
# # st.sidebar.slider(
# #     'Select a range of values',
# #     0.0, 100.0, (25.0, 75.0)
# # )



# @st.cache  # 👈 This function will be cached
# def my_slow_function(arg1, arg2):
#     # Do something really slow in here!
#     return the_output



# import streamlit as st
# import time

# def expensive_computation(a, b):
#     time.sleep(2)  # 👈 This makes the function take 2s to run
#     return a * b

# a = 2
# b = 21
# res = expensive_computation(a, b)

# st.write("Result:", res)




# import streamlit as st
# import time

# @st.cache  # 👈 Added this
# def expensive_computation(a, b):
#     time.sleep(2)  # This makes the function take 2s to run
#     return a * b

# a = 2
# b = 21
# res = expensive_computation(a, b)

# st.write("Result:", res)





# import streamlit as st
# import time

# @st.cache(suppress_st_warning=True)
# def expensive_computation(a, b):
#     st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
#     time.sleep(2)  # This makes the function take 2s to run
#     return a * b

# a = 2
# b = 210  # 👈 Changed this
# res = expensive_computation(a, b)

# st.write("Result:", res)


# import streamlit as st
# import time

# @st.cache(suppress_st_warning=True)
# def expensive_computation(a, b):
#     st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
#     time.sleep(2)  # This makes the function take 2s to run
#     return a * b + 1  # 👈 Added a +1 at the end here

# a = 2
# b = 210
# res = expensive_computation(a, b)

# st.write("Result:", res)




# import streamlit as st
# import time

# def inner_func(a, b):
#     st.write("inner_func(", a, ",", b, ") ran")
#     return a * b

# @st.cache(suppress_st_warning=True)
# def expensive_computation(a, b):
#     st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
#     time.sleep(2)  # This makes the function take 2s to run
#     return inner_func(a, b) + 1

# a = 2
# b = 210
# res = expensive_computation(a, b)

# st.write("Result:", res)



# import streamlit as st
# import time

# def inner_func(a, b):
#     st.write("inner_func(", a, ",", b, ") ran")
#     return a ** b  # 👈 Changed the * to ** here

# @st.cache(suppress_st_warning=True)
# def expensive_computation(a, b):
#     st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
#     time.sleep(2)  # This makes the function take 2s to run
#     return inner_func(a, b) + 1

# a = 2
# b = 21
# res = expensive_computation(a, b)

# st.write("Result:", res)


# import streamlit as st
# import time

# @st.cache(suppress_st_warning=True)
# def expensive_computation(a, b):
#     st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
#     time.sleep(2)  # This makes the function take 2s to run
#     return a * b

# a = 2
# b = st.slider("Pick a number", 0, 10)  # 👈 Changed this
# res = expensive_computation(a, b)

# st.write("Result:", res)



# import streamlit as st
# import time

# @st.cache(suppress_st_warning=True)
# def expensive_computation(a, b):
#     st.write("Cache miss: expensive_computation(", a, ",", b, ") ran")
#     time.sleep(2)  # This makes the function take 2s to run
#     return {"output": a * b}  # 👈 Mutable object

# a = 2
# b = 21
# res = expensive_computation(a, b)

# st.write("Result:", res)

# res["output"] = "result was manually mutated"  # 👈 Mutated cached value

# st.write("Mutated result:", res)



# import yfinance as yf
# import streamlit as st

# st.title("""simple chart""")
# stock_symbol = "TSLA"
# stockdata=yf.Ticker(stock_symbol)
# stockchart=stockdata.history(period="1d",start='2019-7-1', end='2021-4-22')
# st.line_chart(stockchart.Close)
# st.line_chart(stockchart.Volume)




# import streamlit as st
# import pandas as pd
# import numpy as np

# st.title('Uber pickups in NYC')

# DATE_COLUMN = 'date/time'
# DATA_URL = ('https://s3-us-west-2.amazonaws.com/'
#             'streamlit-demo-data/uber-raw-data-sep14.csv.gz')

# @st.cache
# def load_data(nrows):
#     data = pd.read_csv(DATA_URL, nrows=nrows)
#     lowercase = lambda x: str(x).lower()
#     data.rename(lowercase, axis='columns', inplace=True)
#     data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])
#     return data

# data_load_state = st.text('Loading data...')
# data = load_data(10000)
# data_load_state.text("Done! (using st.cache)")

# if st.checkbox('Show raw data'):
#     st.subheader('Raw data')
#     st.write(data)

# st.subheader('Number of pickups by hour')
# hist_values = np.histogram(data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]
# st.bar_chart(hist_values)

# # Some number in the range 0-23
# hour_to_filter = st.slider('hour', 0, 23, 17)
# filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]

# st.subheader('Map of all pickups at %s:00' % hour_to_filter)
# st.map(filtered_data)



# import streamlit as st
# import pandas as pd
# import numpy as np

# st.title('Uber pickups in NYC')

# DATE_COLUMN = 'date/time'
# DATA_URL = ('https://s3-us-west-2.amazonaws.com/'
#          'streamlit-demo-data/uber-raw-data-sep14.csv.gz')


# @st.cache
# def load_data(nrows):
#     data = pd.read_csv(DATA_URL, nrows=nrows)
#     lowercase = lambda x: str(x).lower()
#     data.rename(lowercase, axis='columns', inplace=True)
#     data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])
#     return data


# # Create a text element and let the reader know the data is loading.
# data_load_state = st.text('Loading data...')
# # Load 10,000 rows of data into the dataframe.
# data = load_data(10000)
# # Notify the reader that the data was successfully loaded.
# data_load_state.text("Done! (using st.cache)")


# st.subheader('Raw data')
# st.write(data)

# st.subheader('Number of pickups by hour')


# hist_values = np.histogram(
#     data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]


# st.bar_chart(hist_values)


# st.subheader('Map of all pickups')

# st.map(data)




# hour_to_filter = st.slider('hour', 0, 23, 17) 
# filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]
# st.subheader(f'Map of all pickups at {hour_to_filter}:00')
# st.map(filtered_data)


# st.subheader('Raw data')
# st.write(data)

# if st.checkbox('Show raw data'):
#     st.subheader('Raw data')
#     st.write(data)







# import streamlit as st 
# import numpy as np 
# import pandas as pd
# import matplotlib.pyplot as plt
# from sklearn import datasets
# from sklearn.model_selection import train_test_split

# from sklearn.decomposition import PCA
# from sklearn.svm import SVC
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.ensemble import RandomForestClassifier

# from sklearn.metrics import accuracy_score


# st.title('My first app')
# st.write("Here's our first attempt at using data to create a table:")
# st.write(pd.DataFrame({
#     'first column': [1, 2, 3, 4],
#     'second column': [10, 20, 30, 40]
# }))


# df = pd.DataFrame({
#   'first column': [1, 2, 3, 4],
#   'second column': [10, 20, 30, 40]
# })

# df


# chart_data = pd.DataFrame(
#      np.random.randn(20, 3),
#      columns=['a', 'b', 'c'])

# st.line_chart(chart_data)


# map_data = pd.DataFrame(
#     np.random.randn(1000, 2) / [50, 50] + [37.76, -122.4],
#     columns=['lat', 'lon'])

# st.map(map_data)


# if st.checkbox('Show dataframe'):
#     chart_data = pd.DataFrame(
#        np.random.randn(20, 3),
#        columns=['a', 'b', 'c'])

#     chart_data



# option = st.selectbox(
#     'Which number do you like best?',
#      df['first column'])

# 'You selected: ', option


# left_column, right_column = st.beta_columns(2)
# pressed = left_column.button('Press me?')
# if pressed:
#     right_column.write("Woohoo!")

# expander = st.beta_expander("FAQ")
# expander.write("Here you could put in some really, really long explanations...")





# import time

# 'Starting a long computation...'

# # Add a placeholder
# latest_iteration = st.empty()
# bar = st.progress(0)

# for i in range(100):
#   # Update the progress bar with each iteration.
#   latest_iteration.text(f'Iteration {i+1}')
#   bar.progress(i + 1)
#   time.sleep(0.1)

# '...and now we\'re done!'





# st.title('Okcupid Recommender')

# st.write("""
# # Explore matching recommendation: 
# ### Who is the best match for you?
# """)


# st.date_input('Your Age')


# st.sidebar.selectbox(
#     'Select your sex',
#     ('male', 'female'))


# st.sidebar.selectbox(
#     'Select your orientation',
#     ('straight', 'gay', 'bisexual'))


# st.select_slider('Age you are looking for',options=[20,30,40,50,60,70,80])

# # st.write(f"## {dataset_name} Dataset")

# st.sidebar.selectbox(
#     'Select classifier',
#     ('KNN', 'SVM', 'Random Forest')
# )

# st.button('Hit me')
# st.checkbox('Check me out')
# st.radio('Radio', [1,2,3])
# st.selectbox('Select', [1,2,3])
# st.multiselect('Multiselect', [1,2,3])
# st.slider('Slide me', min_value=0, max_value=10)
# st.select_slider('Slide to select', options=[1,'2'])
# st.text_input('Enter some text')
# st.number_input('Enter a number')
# st.text_area('Area for textual entry')
# st.date_input('Date input')
# st.time_input('Time entry')
# st.file_uploader('File uploader')
# st.color_picker('Pick a color')


# st.text('Fixed width text')
# st.markdown('_Markdown_') # see *
# st.latex(r''' e^{i\pi} + 1 = 0 ''')
# st.write('Most objects') # df, err, func, keras!
# st.write(['st', 'is <', 3]) # see *
# st.title('My title')
# st.header('My header')
# st.subheader('My sub')
# st.code('for i in range(8): foo()')
# * optional kwarg unsafe_allow_html = True


# def get_dataset(name):
#     data = None
#     if name == 'Iris':
#         data = datasets.load_iris()
#     elif name == 'Wine':
#         data = datasets.load_wine()
#     else:
#         data = datasets.load_breast_cancer()
#     X = data.data
#     y = data.target
#     return X, y

# X, y = get_dataset(dataset_name)
# st.write('Shape of dataset:', X.shape)
# st.write('number of classes:', len(np.unique(y)))

# def add_parameter_ui(clf_name):
#     params = dict()
#     if clf_name == 'SVM':
#         C = st.sidebar.slider('C', 0.01, 10.0)
#         params['C'] = C
#     elif clf_name == 'KNN':
#         K = st.sidebar.slider('K', 1, 15)
#         params['K'] = K
#     else:
#         max_depth = st.sidebar.slider('max_depth', 2, 15)
#         params['max_depth'] = max_depth
#         n_estimators = st.sidebar.slider('n_estimators', 1, 100)
#         params['n_estimators'] = n_estimators
#     return params

# # params = add_parameter_ui(classifier_name)

# def get_classifier(clf_name, params):
#     clf = None
#     if clf_name == 'SVM':
#         clf = SVC(C=params['C'])
#     elif clf_name == 'KNN':
#         clf = KNeighborsClassifier(n_neighbors=params['K'])
#     else:
#         clf = clf = RandomForestClassifier(n_estimators=params['n_estimators'], 
#             max_depth=params['max_depth'], random_state=1234)
#     return clf

# clf = get_classifier(classifier_name, params)
# #### CLASSIFICATION ####

# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)

# clf.fit(X_train, y_train)
# y_pred = clf.predict(X_test)

# acc = accuracy_score(y_test, y_pred)

# st.write(f'Classifier = {classifier_name}')
# st.write(f'Accuracy =', acc)

# #### PLOT DATASET ####
# # Project the data onto the 2 primary principal components
# pca = PCA(2)
# X_projected = pca.fit_transform(X)

# x1 = X_projected[:, 0]
# x2 = X_projected[:, 1]

# fig = plt.figure()
# plt.scatter(x1, x2,
#         c=y, alpha=0.8,
#         cmap='viridis')

# plt.xlabel('Principal Component 1')
# plt.ylabel('Principal Component 2')
# plt.colorbar()

# #plt.show()
# st.pyplot(fig)
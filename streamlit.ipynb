{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "better-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.59.tar.gz (25 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from yfinance) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from yfinance) (1.19.5)\n",
      "Requirement already satisfied: requests>=2.20 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from yfinance) (2.25.1)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.9.tar.gz (8.1 kB)\n",
      "Requirement already satisfied: lxml>=4.5.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from yfinance) (4.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pandas>=0.24->yfinance) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests>=2.20->yfinance) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests>=2.20->yfinance) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests>=2.20->yfinance) (2.10)\n",
      "Building wheels for collected packages: yfinance, multitasking\n",
      "  Building wheel for yfinance (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for yfinance: filename=yfinance-0.1.59-py2.py3-none-any.whl size=23442 sha256=1f19eb360563c178c521f00526213855ad33d03449d7b6c434a14a92f8baa7bd\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/26/af/8b/fac1b47dffef567f945641cdc9b67bb25fae5725d462a8cf81\n",
      "  Building wheel for multitasking (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.9-py3-none-any.whl size=8368 sha256=5e185e950171493e002d0c6e84a1b6726a49ae7167fa5bb617cc5d9227cc8b18\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/ae/25/47/4d68431a7ec1b6c4b5233365934b74c1d4e665bf5f968d363a\n",
      "Successfully built yfinance multitasking\n",
      "Installing collected packages: multitasking, yfinance\n",
      "Successfully installed multitasking-0.0.9 yfinance-0.1.59\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "packed-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-0.80.0-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.2 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting as\n",
      "  Downloading as-0.1-py3-none-any.whl (2.2 kB)\n",
      "Collecting st\n",
      "  Downloading st-0.0.8.zip (7.3 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (8.1.0)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (3.15.2)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (20.9)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727 kB 106.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from streamlit) (4.2.1)\n",
      "Collecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111 kB 77.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: click>=7.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: pyarrow in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: toml in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: pandas>=0.21.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (1.2.2)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.6.2-py2.py3-none-any.whl (4.2 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.2 MB 93.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (2.8.1)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (2.25.1)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.0.3-py3-none-manylinux2014_x86_64.whl (74 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74 kB 5.6 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting tzlocal\n",
      "  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tornado>=5.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (6.1)\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
      "Collecting gitpython\n",
      "  Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159 kB 105.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from streamlit) (1.19.5)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: entrypoints in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: jsonschema in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: toolz in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pandas>=0.21.0->streamlit) (2021.1)\n",
      "Requirement already satisfied: six>=1.9 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
      "Requirement already satisfied: jupyter-client in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (6.1.11)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.20.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (49.6.0.post20210108)\n",
      "Requirement already satisfied: decorator in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.16)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
      "Requirement already satisfied: backcall in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: pygments in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: jupyter-core in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
      "Requirement already satisfied: ipython-genutils in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from jsonschema->altair>=3.2.0->streamlit) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from jsonschema->altair>=3.2.0->streamlit) (20.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from jsonschema->altair>=3.2.0->streamlit) (3.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.2.0)\n",
      "Requirement already satisfied: prometheus-client in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.0)\n",
      "Requirement already satisfied: nbconvert in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.2)\n",
      "Requirement already satisfied: argon2-cffi in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (22.0.3)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.20)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63 kB 3.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from importlib-metadata->jsonschema->altair>=3.2.0->streamlit) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from importlib-metadata->jsonschema->altair>=3.2.0->streamlit) (3.7.4.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: testpath in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.2)\n",
      "Requirement already satisfied: bleach in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
      "Requirement already satisfied: nest-asyncio in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: async-generator in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.10)\n",
      "Requirement already satisfied: webencodings in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from packaging->streamlit) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->streamlit) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->streamlit) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->streamlit) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->streamlit) (2.10)\n",
      "Building wheels for collected packages: st, blinker\n",
      "  Building wheel for st (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for st: filename=st-0.0.8-py3-none-any.whl size=5309 sha256=2e989a988a27ce73764e18b7a41cb7d3671e9d532d4a8d734dd443414d26da30\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/eb/49/d8/45d9a6ab41ef59cb84d2c24a1992d85371d866472593e9e9e4\n",
      "  Building wheel for blinker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13451 sha256=3c66473eb6dbf4915fc9099a59a63e943bb5f2e5c2f953ef04378c7a751bfa1b\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
      "Successfully built st blinker\n",
      "Installing collected packages: smmap, gitdb, watchdog, validators, tzlocal, pydeck, gitpython, blinker, base58, astor, altair, streamlit, st, as\n",
      "Successfully installed altair-4.1.0 as-0.1 astor-0.8.1 base58-2.1.0 blinker-1.4 gitdb-4.0.7 gitpython-3.1.14 pydeck-0.6.2 smmap-4.0.0 st-0.0.8 streamlit-0.80.0 tzlocal-2.1 validators-0.18.2 watchdog-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blind-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import streamlit as st\n",
    "\n",
    "# st.title(\"\"\"simple chart\"\"\")\n",
    "# stock_symbol = \"TSLA\"\n",
    "# stockdata=yf.Ticker(stock_symbol)\n",
    "# stockchart=stockdata.history(period=\"1d\",start='2019-7-1', end='2021-4-22')\n",
    "# st.line_chart(stockchart.Close)\n",
    "# st.line_chart(stockchart.Volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from streamlit_lottie import st_lottie\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import RendererAgg\n",
    "from matplotlib.figure import Figure\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import random\n",
    "\n",
    "_lock = RendererAgg.lock\n",
    "plt.style.use('default')\n",
    "\n",
    "# SETUP ------------------------------------------------------------------------\n",
    "\n",
    "st.title('Okcupid Match Making Recommender')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write(\"\"\"\n",
    "‚ÄúThe best and most beautiful things in the world cannot be seen or even touched. \\n\n",
    "They must be felt with the heart.‚Äù  ‚Äì Helen Keller \"\"\")\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write(\"\"\"\n",
    "‚Äú‚ÄôTis better to have loved and lost, than never to have loved at all‚Äù  ‚Äì Alfred, Lord Tennyson \n",
    "\"\"\")\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write(\"\"\"\n",
    "‚ÄúWe come to love not by finding a perfect person, \\n \n",
    "but by learning to see an imperfect person perfectly.‚Äù \"\"\")\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write(\"\"\"\n",
    "‚ÄúLove doesn‚Äôt make the world go round. Love is what makes the ride worthwhile‚Äù ‚Äì Franklin P. Jones  \"\"\")\n",
    "\n",
    "\n",
    "# SIDE BAR ------------------------------------------------------------------------\n",
    "\n",
    "# Cached function that returns a mutable object with a random number in the range 0-100\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def seed():\n",
    "    return {'seed': random.randint(0, 100)} # Mutable (dict)\n",
    "\n",
    "# Random state for points generation randomly selected by calling the cached function seed()\n",
    "# In this way the points distribution generated by make_blobs is conserved when app is rerun\n",
    "random_state = seed()\n",
    "\n",
    "\n",
    "# Button to reset points by mutating the cached dict value\n",
    "if st.sidebar.button('Reset points', key='123'):\n",
    "    random_state['seed'] = random.randint(0, 100) # Mutated cached value\n",
    "\n",
    "\n",
    "# Showing the current random_state\n",
    "st.sidebar.write('Seed = ', random_state['seed'])\n",
    "\n",
    "\n",
    "# Slider to select the standard deviation of clusters generated by make_blobs generator\n",
    "cluster_std = st.sidebar.slider('Dispersion', 0.2, 3.0, 0.2, 0.2)\n",
    "\n",
    "\n",
    "# Dropdown list to select number of clusters\n",
    "n_clusters = st.sidebar.selectbox('Number of clusters', range(1, 10))\n",
    "\n",
    "\n",
    "# ROW 0 ------------------------------------------------------------------------\n",
    "\n",
    "row0_spacer1, row0_1, row0_spacer2, row0_2, row0_spacer3, row0_3, row0_spacer_4 = st.beta_columns(\n",
    "    (.56, 1.6, .56, 1.6, .56, 1.6, .56)\n",
    "    )\n",
    "\n",
    "with row0_1:\n",
    "\n",
    "    def load_lottieurl(url: str):\n",
    "        r = requests.get(url)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        return r.json()\n",
    "\n",
    "    lottie_url1 = \"https://assets3.lottiefiles.com/packages/lf20_n5icqxkw.json\"\n",
    "    lottie_json1 = load_lottieurl(lottie_url1)\n",
    "    st_lottie(lottie_json1)\n",
    "\n",
    "\n",
    "with row0_2:\n",
    "    lottie_url = \"https://assets3.lottiefiles.com/packages/lf20_hewaysm0.json\"\n",
    "    lottie_json = load_lottieurl(lottie_url)\n",
    "    st_lottie(lottie_json)\n",
    "\n",
    "\n",
    "with row0_3:\n",
    "\n",
    "    lottie_url2 = \"https://assets5.lottiefiles.com/private_files/lf30_6jzgknvg.json\"\n",
    "    lottie_json2 = load_lottieurl(lottie_url2)\n",
    "    st_lottie(lottie_json2)\n",
    "\n",
    "\n",
    "\n",
    "# ROW 1 ------------------------------------------------------------------------\n",
    "\n",
    "row1_spacer1, row1_1, row1_spacer2, row1_2, row1_spacer3 = st.beta_columns(\n",
    "    (.1, 2, 1.5, 1, .1)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def get_pd():\n",
    "    #plyer data\n",
    "    col_list2 = ['id_','nickname','age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
    "       'drugs', 'education', 'height', 'job', 'offspring', 'pets', 'religion',\n",
    "       'sign', 'smokes','headshot_url']\n",
    "\n",
    "    player_data_ = pd.read_csv('https://github.com/bethsung1011/capstone_3/blob/main/profile1.csv?raw=True',\n",
    "                                low_memory=False, usecols=col_list2)\n",
    "\n",
    "    return player_data_\n",
    "\n",
    "player_data_ = get_pd()\n",
    "\n",
    "\n",
    "# ROW 2 ------------------------------------------------------------------------\n",
    "\n",
    "row2_spacer1, row2_1, row2_spacer2, row2_2, row2_spacer3,  row2_3, row2_spacer4= st.beta_columns(\n",
    "    (.1,1.6,.1,1.6,.1,1.6,.1)\n",
    "    )\n",
    "\n",
    "with row2_1:\n",
    "    records=player_data_['nickname'].to_list()\n",
    "        # 'Miranda', 'Ken', 'Beebeep Bajeep', 'puppy', 'Samu', 'Wayne', 'Tom', 'George Timberman', 'Fox Creek', 'doge', 'Roonie', 'Toby', 'Somebody', 'j']\n",
    "    selected_data = st.selectbox('Select Who You Are', options=records)\n",
    "\n",
    "\n",
    "with row2_2:\n",
    "\n",
    "    url = {'Miranda': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5209176-035clefairy.png',\n",
    " 'Ken': 'https://comicvine1.cbsistatic.com/uploads/original/6/63099/1998241-ep067.png',\n",
    " 'Beebeep Bajeep': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198759-068machamp.png',\n",
    " 'puppy': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198898-003venusaur-mega.png',\n",
    " 'Samu': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5213189-042golbat.png',\n",
    " 'Wayne': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198880-007squirtle.png',\n",
    " 'Tom': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/4357615-250px-094gengar.png',\n",
    " 'George Timberman': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5215180-175togepi.png',\n",
    " 'Fox Creek': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198871-143snorlax.png',\n",
    " 'doge': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198763-052meowth.png',\n",
    " 'Roonie': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5212960-107hitmonchan.png',\n",
    " 'Toby': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198641-006charizard-mega_y.png',\n",
    " 'Somebody': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5198809-057primeape.png',\n",
    " 'j': 'https://comicvine1.cbsistatic.com/uploads/original/11/114183/5212919-095onix.png'}\n",
    "\n",
    "\n",
    "    st.subheader('About Me')\n",
    "    st.image(url.get(selected_data), width=200)\n",
    "\n",
    "\n",
    "with row2_3:\n",
    "\n",
    "\n",
    "    player_filter = player_data_.loc[player_data_['nickname'] == selected_data]\n",
    "  \n",
    "    st.subheader('     ')\n",
    "    st.text(        f\"Name: {player_filter['nickname'].to_string(index=False).lstrip()}\"        )\n",
    "    st.text(        f\"Age: {player_filter['age'].to_string(index=False).lstrip()}\"        )\n",
    "    st.text(        f\"Status: {player_filter['status'].to_string(index=False).lstrip()}\"        )\n",
    "    st.text(        f\"Orientation: {player_filter['orientation'].to_string(index=False).lstrip()}\"        )\n",
    "    st.text(        f\"Diet: {player_filter['diet'].to_string(index=False).lstrip()}\"        )\n",
    "    st.text(        f\"Job: {player_filter['job'].to_string(index=False).lstrip()}\"        )    \n",
    "    # st.text(        f\"Job: {player_filter['job'].astype(int).to_string(index=False).lstrip()}\"        )\n",
    "    st.text(' ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ROW 3 ------------------------------------------------------------------------\n",
    "\n",
    "row3_spacer1, row3_1, row3_spacer2, row3_2, row3_spacer3 = st.beta_columns(\n",
    "    (.1, 1.6, .1, 1.6, .1)\n",
    "    )\n",
    "\n",
    "with row3_1:\n",
    "    lottie_url = \"https://assets9.lottiefiles.com/packages/lf20_xldshlit.json\"\n",
    "    lottie_json = load_lottieurl(lottie_url)\n",
    "    st_lottie(lottie_json)\n",
    "\n",
    "with row3_2:\n",
    "    row3_1.title('Thanks!')\n",
    "    row3_2.write('')\n",
    "    row3_2.subheader('made by [Beth Sung](https://www.linkedin.com/in/beth-sung/)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# st.text('This will appear first')\n",
    "# # Appends some text to the app.\n",
    "\n",
    "# my_slot1 = st.empty()\n",
    "# # Appends an empty slot to the app. We'll use this later.\n",
    "\n",
    "# my_slot2 = st.empty()\n",
    "# # Appends another empty slot.\n",
    "\n",
    "# st.text('This will appear last')\n",
    "# # Appends some more text to the app.\n",
    "\n",
    "# my_slot1.text('This will appear second')\n",
    "# # Replaces the first empty slot with a text string.\n",
    "\n",
    "# my_slot2.line_chart(np.random.randn(20, 2))\n",
    "# # Replaces the second empty slot with a chart.\n",
    "\n",
    "\n",
    "# progress_bar = st.progress(0)\n",
    "# status_text = st.empty()\n",
    "# chart = st.line_chart(np.random.randn(10, 2))\n",
    "\n",
    "# for i in range(100):\n",
    "#     # Update progress bar.\n",
    "#     progress_bar.progress(i + 1)\n",
    "\n",
    "#     new_rows = np.random.randn(10, 2)\n",
    "\n",
    "#     # Update status text.\n",
    "#     status_text.text(\n",
    "#         'The latest random number is: %s' % new_rows[-1, 1])\n",
    "\n",
    "#     # Append data to the chart.\n",
    "#     chart.add_rows(new_rows)\n",
    "\n",
    "#     # Pretend we're doing some computation that takes time.\n",
    "#     time.sleep(0.1)\n",
    "\n",
    "# status_text.text('Done!')\n",
    "# st.balloons()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# # Get some data.\n",
    "# data = np.random.randn(10, 2)\n",
    "\n",
    "# # Show the data as a chart.\n",
    "# chart = st.line_chart(data)\n",
    "\n",
    "# # Wait 1 second, so the change is clearer.\n",
    "# time.sleep(1)\n",
    "\n",
    "# # Grab some more data.\n",
    "# data2 = np.random.randn(10, 2)\n",
    "\n",
    "# # Append the new data to the existing chart.\n",
    "# chart.add_rows(data2)\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# dataframe = np.random.randn(10, 20)\n",
    "# st.dataframe(dataframe)\n",
    "\n",
    "\n",
    "# dataframe = pd.DataFrame(\n",
    "#     np.random.randn(10, 20),\n",
    "#     columns=('col %d' % i for i in range(20)))\n",
    "\n",
    "# st.dataframe(dataframe.style.highlight_max(axis=0))\n",
    "\n",
    "\n",
    "\n",
    "# dataframe = pd.DataFrame(\n",
    "#     np.random.randn(10, 20),\n",
    "#     columns=('col %d' % i for i in range(20)))\n",
    "# st.table(dataframe)\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# x = st.slider('x')  # üëà this is a widget\n",
    "# st.write(x, 'squared is', x * x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "\n",
    "# left_column, right_column = st.beta_columns(2)\n",
    "# # You can use a column just like st.sidebar:\n",
    "# left_column.button('Press me!')\n",
    "\n",
    "# # Or even better, call Streamlit functions inside a \"with\" block:\n",
    "# with right_column:\n",
    "#     chosen = st.radio(\n",
    "#         'Sorting hat',\n",
    "#         (\"Gryffindor\", \"Ravenclaw\", \"Hufflepuff\", \"Slytherin\"))\n",
    "#     st.write(f\"You are in {chosen} house!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # import streamlit as st\n",
    "\n",
    "# # # Add a selectbox to the sidebar:\n",
    "# # st.sidebar.selectbox(\n",
    "# #     'How would you like to be contacted?',\n",
    "# #     ('Email', 'Home phone', 'Mobile phone')\n",
    "# # )\n",
    "\n",
    "\n",
    "\n",
    "# # # Add a slider to the sidebar:\n",
    "# # st.sidebar.slider(\n",
    "# #     'Select a range of values',\n",
    "# #     0.0, 100.0, (25.0, 75.0)\n",
    "# # )\n",
    "\n",
    "\n",
    "\n",
    "# @st.cache  # üëà This function will be cached\n",
    "# def my_slow_function(arg1, arg2):\n",
    "#     # Do something really slow in here!\n",
    "#     return the_output\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import time\n",
    "\n",
    "# def expensive_computation(a, b):\n",
    "#     time.sleep(2)  # üëà This makes the function take 2s to run\n",
    "#     return a * b\n",
    "\n",
    "# a = 2\n",
    "# b = 21\n",
    "# res = expensive_computation(a, b)\n",
    "\n",
    "# st.write(\"Result:\", res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import time\n",
    "\n",
    "# @st.cache  # üëà Added this\n",
    "# def expensive_computation(a, b):\n",
    "#     time.sleep(2)  # This makes the function take 2s to run\n",
    "#     return a * b\n",
    "\n",
    "# a = 2\n",
    "# b = 21\n",
    "# res = expensive_computation(a, b)\n",
    "\n",
    "# st.write(\"Result:\", res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import time\n",
    "\n",
    "# @st.cache(suppress_st_warning=True)\n",
    "# def expensive_computation(a, b):\n",
    "#     st.write(\"Cache miss: expensive_computation(\", a, \",\", b, \") ran\")\n",
    "#     time.sleep(2)  # This makes the function take 2s to run\n",
    "#     return a * b\n",
    "\n",
    "# a = 2\n",
    "# b = 210  # üëà Changed this\n",
    "# res = expensive_computation(a, b)\n",
    "\n",
    "# st.write(\"Result:\", res)\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import time\n",
    "\n",
    "# @st.cache(suppress_st_warning=True)\n",
    "# def expensive_computation(a, b):\n",
    "#     st.write(\"Cache miss: expensive_computation(\", a, \",\", b, \") ran\")\n",
    "#     time.sleep(2)  # This makes the function take 2s to run\n",
    "#     return a * b + 1  # üëà Added a +1 at the end here\n",
    "\n",
    "# a = 2\n",
    "# b = 210\n",
    "# res = expensive_computation(a, b)\n",
    "\n",
    "# st.write(\"Result:\", res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import time\n",
    "\n",
    "# def inner_func(a, b):\n",
    "#     st.write(\"inner_func(\", a, \",\", b, \") ran\")\n",
    "#     return a * b\n",
    "\n",
    "# @st.cache(suppress_st_warning=True)\n",
    "# def expensive_computation(a, b):\n",
    "#     st.write(\"Cache miss: expensive_computation(\", a, \",\", b, \") ran\")\n",
    "#     time.sleep(2)  # This makes the function take 2s to run\n",
    "#     return inner_func(a, b) + 1\n",
    "\n",
    "# a = 2\n",
    "# b = 210\n",
    "# res = expensive_computation(a, b)\n",
    "\n",
    "# st.write(\"Result:\", res)\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import time\n",
    "\n",
    "# def inner_func(a, b):\n",
    "#     st.write(\"inner_func(\", a, \",\", b, \") ran\")\n",
    "#     return a ** b  # üëà Changed the * to ** here\n",
    "\n",
    "# @st.cache(suppress_st_warning=True)\n",
    "# def expensive_computation(a, b):\n",
    "#     st.write(\"Cache miss: expensive_computation(\", a, \",\", b, \") ran\")\n",
    "#     time.sleep(2)  # This makes the function take 2s to run\n",
    "#     return inner_func(a, b) + 1\n",
    "\n",
    "# a = 2\n",
    "# b = 21\n",
    "# res = expensive_computation(a, b)\n",
    "\n",
    "# st.write(\"Result:\", res)\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import time\n",
    "\n",
    "# @st.cache(suppress_st_warning=True)\n",
    "# def expensive_computation(a, b):\n",
    "#     st.write(\"Cache miss: expensive_computation(\", a, \",\", b, \") ran\")\n",
    "#     time.sleep(2)  # This makes the function take 2s to run\n",
    "#     return a * b\n",
    "\n",
    "# a = 2\n",
    "# b = st.slider(\"Pick a number\", 0, 10)  # üëà Changed this\n",
    "# res = expensive_computation(a, b)\n",
    "\n",
    "# st.write(\"Result:\", res)\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import time\n",
    "\n",
    "# @st.cache(suppress_st_warning=True)\n",
    "# def expensive_computation(a, b):\n",
    "#     st.write(\"Cache miss: expensive_computation(\", a, \",\", b, \") ran\")\n",
    "#     time.sleep(2)  # This makes the function take 2s to run\n",
    "#     return {\"output\": a * b}  # üëà Mutable object\n",
    "\n",
    "# a = 2\n",
    "# b = 21\n",
    "# res = expensive_computation(a, b)\n",
    "\n",
    "# st.write(\"Result:\", res)\n",
    "\n",
    "# res[\"output\"] = \"result was manually mutated\"  # üëà Mutated cached value\n",
    "\n",
    "# st.write(\"Mutated result:\", res)\n",
    "\n",
    "\n",
    "\n",
    "# import yfinance as yf\n",
    "# import streamlit as st\n",
    "\n",
    "# st.title(\"\"\"simple chart\"\"\")\n",
    "# stock_symbol = \"TSLA\"\n",
    "# stockdata=yf.Ticker(stock_symbol)\n",
    "# stockchart=stockdata.history(period=\"1d\",start='2019-7-1', end='2021-4-22')\n",
    "# st.line_chart(stockchart.Close)\n",
    "# st.line_chart(stockchart.Volume)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# st.title('Uber pickups in NYC')\n",
    "\n",
    "# DATE_COLUMN = 'date/time'\n",
    "# DATA_URL = ('https://s3-us-west-2.amazonaws.com/'\n",
    "#             'streamlit-demo-data/uber-raw-data-sep14.csv.gz')\n",
    "\n",
    "# @st.cache\n",
    "# def load_data(nrows):\n",
    "#     data = pd.read_csv(DATA_URL, nrows=nrows)\n",
    "#     lowercase = lambda x: str(x).lower()\n",
    "#     data.rename(lowercase, axis='columns', inplace=True)\n",
    "#     data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])\n",
    "#     return data\n",
    "\n",
    "# data_load_state = st.text('Loading data...')\n",
    "# data = load_data(10000)\n",
    "# data_load_state.text(\"Done! (using st.cache)\")\n",
    "\n",
    "# if st.checkbox('Show raw data'):\n",
    "#     st.subheader('Raw data')\n",
    "#     st.write(data)\n",
    "\n",
    "# st.subheader('Number of pickups by hour')\n",
    "# hist_values = np.histogram(data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]\n",
    "# st.bar_chart(hist_values)\n",
    "\n",
    "# # Some number in the range 0-23\n",
    "# hour_to_filter = st.slider('hour', 0, 23, 17)\n",
    "# filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]\n",
    "\n",
    "# st.subheader('Map of all pickups at %s:00' % hour_to_filter)\n",
    "# st.map(filtered_data)\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# st.title('Uber pickups in NYC')\n",
    "\n",
    "# DATE_COLUMN = 'date/time'\n",
    "# DATA_URL = ('https://s3-us-west-2.amazonaws.com/'\n",
    "#          'streamlit-demo-data/uber-raw-data-sep14.csv.gz')\n",
    "\n",
    "\n",
    "# @st.cache\n",
    "# def load_data(nrows):\n",
    "#     data = pd.read_csv(DATA_URL, nrows=nrows)\n",
    "#     lowercase = lambda x: str(x).lower()\n",
    "#     data.rename(lowercase, axis='columns', inplace=True)\n",
    "#     data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])\n",
    "#     return data\n",
    "\n",
    "\n",
    "# # Create a text element and let the reader know the data is loading.\n",
    "# data_load_state = st.text('Loading data...')\n",
    "# # Load 10,000 rows of data into the dataframe.\n",
    "# data = load_data(10000)\n",
    "# # Notify the reader that the data was successfully loaded.\n",
    "# data_load_state.text(\"Done! (using st.cache)\")\n",
    "\n",
    "\n",
    "# st.subheader('Raw data')\n",
    "# st.write(data)\n",
    "\n",
    "# st.subheader('Number of pickups by hour')\n",
    "\n",
    "\n",
    "# hist_values = np.histogram(\n",
    "#     data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]\n",
    "\n",
    "\n",
    "# st.bar_chart(hist_values)\n",
    "\n",
    "\n",
    "# st.subheader('Map of all pickups')\n",
    "\n",
    "# st.map(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# hour_to_filter = st.slider('hour', 0, 23, 17) \n",
    "# filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]\n",
    "# st.subheader(f'Map of all pickups at {hour_to_filter}:00')\n",
    "# st.map(filtered_data)\n",
    "\n",
    "\n",
    "# st.subheader('Raw data')\n",
    "# st.write(data)\n",
    "\n",
    "# if st.checkbox('Show raw data'):\n",
    "#     st.subheader('Raw data')\n",
    "#     st.write(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import streamlit as st \n",
    "# import numpy as np \n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn import datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# st.title('My first app')\n",
    "# st.write(\"Here's our first attempt at using data to create a table:\")\n",
    "# st.write(pd.DataFrame({\n",
    "#     'first column': [1, 2, 3, 4],\n",
    "#     'second column': [10, 20, 30, 40]\n",
    "# }))\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#   'first column': [1, 2, 3, 4],\n",
    "#   'second column': [10, 20, 30, 40]\n",
    "# })\n",
    "\n",
    "# df\n",
    "\n",
    "\n",
    "# chart_data = pd.DataFrame(\n",
    "#      np.random.randn(20, 3),\n",
    "#      columns=['a', 'b', 'c'])\n",
    "\n",
    "# st.line_chart(chart_data)\n",
    "\n",
    "\n",
    "# map_data = pd.DataFrame(\n",
    "#     np.random.randn(1000, 2) / [50, 50] + [37.76, -122.4],\n",
    "#     columns=['lat', 'lon'])\n",
    "\n",
    "# st.map(map_data)\n",
    "\n",
    "\n",
    "# if st.checkbox('Show dataframe'):\n",
    "#     chart_data = pd.DataFrame(\n",
    "#        np.random.randn(20, 3),\n",
    "#        columns=['a', 'b', 'c'])\n",
    "\n",
    "#     chart_data\n",
    "\n",
    "\n",
    "\n",
    "# option = st.selectbox(\n",
    "#     'Which number do you like best?',\n",
    "#      df['first column'])\n",
    "\n",
    "# 'You selected: ', option\n",
    "\n",
    "\n",
    "# left_column, right_column = st.beta_columns(2)\n",
    "# pressed = left_column.button('Press me?')\n",
    "# if pressed:\n",
    "#     right_column.write(\"Woohoo!\")\n",
    "\n",
    "# expander = st.beta_expander(\"FAQ\")\n",
    "# expander.write(\"Here you could put in some really, really long explanations...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import time\n",
    "\n",
    "# 'Starting a long computation...'\n",
    "\n",
    "# # Add a placeholder\n",
    "# latest_iteration = st.empty()\n",
    "# bar = st.progress(0)\n",
    "\n",
    "# for i in range(100):\n",
    "#   # Update the progress bar with each iteration.\n",
    "#   latest_iteration.text(f'Iteration {i+1}')\n",
    "#   bar.progress(i + 1)\n",
    "#   time.sleep(0.1)\n",
    "\n",
    "# '...and now we\\'re done!'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# st.title('Okcupid Recommender')\n",
    "\n",
    "# st.write(\"\"\"\n",
    "# # Explore matching recommendation: \n",
    "# ### Who is the best match for you?\n",
    "# \"\"\")\n",
    "\n",
    "\n",
    "# st.date_input('Your Age')\n",
    "\n",
    "\n",
    "# st.sidebar.selectbox(\n",
    "#     'Select your sex',\n",
    "#     ('male', 'female'))\n",
    "\n",
    "\n",
    "# st.sidebar.selectbox(\n",
    "#     'Select your orientation',\n",
    "#     ('straight', 'gay', 'bisexual'))\n",
    "\n",
    "\n",
    "# st.select_slider('Age you are looking for',options=[20,30,40,50,60,70,80])\n",
    "\n",
    "# # st.write(f\"## {dataset_name} Dataset\")\n",
    "\n",
    "# st.sidebar.selectbox(\n",
    "#     'Select classifier',\n",
    "#     ('KNN', 'SVM', 'Random Forest')\n",
    "# )\n",
    "\n",
    "# st.button('Hit me')\n",
    "# st.checkbox('Check me out')\n",
    "# st.radio('Radio', [1,2,3])\n",
    "# st.selectbox('Select', [1,2,3])\n",
    "# st.multiselect('Multiselect', [1,2,3])\n",
    "# st.slider('Slide me', min_value=0, max_value=10)\n",
    "# st.select_slider('Slide to select', options=[1,'2'])\n",
    "# st.text_input('Enter some text')\n",
    "# st.number_input('Enter a number')\n",
    "# st.text_area('Area for textual entry')\n",
    "# st.date_input('Date input')\n",
    "# st.time_input('Time entry')\n",
    "# st.file_uploader('File uploader')\n",
    "# st.color_picker('Pick a color')\n",
    "\n",
    "\n",
    "# st.text('Fixed width text')\n",
    "# st.markdown('_Markdown_') # see *\n",
    "# st.latex(r''' e^{i\\pi} + 1 = 0 ''')\n",
    "# st.write('Most objects') # df, err, func, keras!\n",
    "# st.write(['st', 'is <', 3]) # see *\n",
    "# st.title('My title')\n",
    "# st.header('My header')\n",
    "# st.subheader('My sub')\n",
    "# st.code('for i in range(8): foo()')\n",
    "# * optional kwarg unsafe_allow_html = True\n",
    "\n",
    "\n",
    "# def get_dataset(name):\n",
    "#     data = None\n",
    "#     if name == 'Iris':\n",
    "#         data = datasets.load_iris()\n",
    "#     elif name == 'Wine':\n",
    "#         data = datasets.load_wine()\n",
    "#     else:\n",
    "#         data = datasets.load_breast_cancer()\n",
    "#     X = data.data\n",
    "#     y = data.target\n",
    "#     return X, y\n",
    "\n",
    "# X, y = get_dataset(dataset_name)\n",
    "# st.write('Shape of dataset:', X.shape)\n",
    "# st.write('number of classes:', len(np.unique(y)))\n",
    "\n",
    "# def add_parameter_ui(clf_name):\n",
    "#     params = dict()\n",
    "#     if clf_name == 'SVM':\n",
    "#         C = st.sidebar.slider('C', 0.01, 10.0)\n",
    "#         params['C'] = C\n",
    "#     elif clf_name == 'KNN':\n",
    "#         K = st.sidebar.slider('K', 1, 15)\n",
    "#         params['K'] = K\n",
    "#     else:\n",
    "#         max_depth = st.sidebar.slider('max_depth', 2, 15)\n",
    "#         params['max_depth'] = max_depth\n",
    "#         n_estimators = st.sidebar.slider('n_estimators', 1, 100)\n",
    "#         params['n_estimators'] = n_estimators\n",
    "#     return params\n",
    "\n",
    "# # params = add_parameter_ui(classifier_name)\n",
    "\n",
    "# def get_classifier(clf_name, params):\n",
    "#     clf = None\n",
    "#     if clf_name == 'SVM':\n",
    "#         clf = SVC(C=params['C'])\n",
    "#     elif clf_name == 'KNN':\n",
    "#         clf = KNeighborsClassifier(n_neighbors=params['K'])\n",
    "#     else:\n",
    "#         clf = clf = RandomForestClassifier(n_estimators=params['n_estimators'], \n",
    "#             max_depth=params['max_depth'], random_state=1234)\n",
    "#     return clf\n",
    "\n",
    "# clf = get_classifier(classifier_name, params)\n",
    "# #### CLASSIFICATION ####\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# st.write(f'Classifier = {classifier_name}')\n",
    "# st.write(f'Accuracy =', acc)\n",
    "\n",
    "# #### PLOT DATASET ####\n",
    "# # Project the data onto the 2 primary principal components\n",
    "# pca = PCA(2)\n",
    "# X_projected = pca.fit_transform(X)\n",
    "\n",
    "# x1 = X_projected[:, 0]\n",
    "# x2 = X_projected[:, 1]\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.scatter(x1, x2,\n",
    "#         c=y, alpha=0.8,\n",
    "#         cmap='viridis')\n",
    "\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.colorbar()\n",
    "\n",
    "# #plt.show()\n",
    "# st.pyplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-italic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-madness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-supervision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "provincial-child",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 298 fields in line 128, saw 440\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-82cd66168eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://drive.google.com/file/d/1NwO4x-V065SIPRRH2QjSl_djkUvgOlHk/view?usp=sharing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 298 fields in line 128, saw 440\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "url=\"https://drive.google.com/file/d/1NwO4x-V065SIPRRH2QjSl_djkUvgOlHk/view?usp=sharing\"\n",
    "s=requests.get(url).content\n",
    "c=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-formation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
